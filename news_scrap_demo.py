# ms-ai-demo/news_scrap_demo.py
import json
import collections
from urllib.parse import urlparse
import streamlit as st

from news_scraper import search_news, search_news_multi, NewsError
from storage_utils import (
    upload_json,  # (í˜„ì¬ í™”ë©´ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ import ìœ ì§€í•´ë„ ë¬´ë°©)
    sas_url,
    download_bytes,
    to_csv_bytes,
    public_blob_url,
    generate_docx_bytes,
    make_docx_filename_from_query,
    upload_docx,
)


def render_news_scrap_demo():

    # â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _attach_site_filters(q: str, sites_text: str) -> str:
        """ì¤„ë°”ê¿ˆ ì…ë ¥ëœ ì‚¬ì´íŠ¸ ëª©ë¡ì„ site: í•„í„°ë¡œ ë¬¶ì–´ ì¿¼ë¦¬ì— í•©ì„±"""
        sites = [s.strip() for s in (sites_text or "").splitlines() if s.strip()]
        if not sites:
            return q
        site_expr = " OR ".join([f"site:{s}" for s in sites])
        return f"({q}) AND ({site_expr})"

    def _domain(u: str) -> str:
        try:
            netloc = urlparse(u or "").netloc.lower()
            return netloc.replace("www.", "")
        except Exception:
            return ""

    # â”€â”€ ê¸°ë³¸ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # ì„¸ì…˜ ìƒíƒœ í‚¤ ë³´ì¥
    if "items" not in st.session_state:
        st.session_state["items"] = []
    if "blob_info" not in st.session_state:
        st.session_state["blob_info"] = None
    if "docx_blob_info" not in st.session_state:
        st.session_state["docx_blob_info"] = None

    # â”€â”€ ê²€ìƒ‰ í¼ (ë¦¬ëŸ°ì—ë„ ìƒíƒœ ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.form("search_form", clear_on_submit=False):
        st.caption("ê²€ìƒ‰ ì˜µì…˜")
        q = st.text_area("í‚¤ì›Œë“œ / ì§ˆì˜", "KT", height=90)
        freshness = st.selectbox("ê¸°ê°„(freshness)", ["Day", "Week", "Month"], index=2)
        count = st.slider("ê°œìˆ˜", 3, 30, 10, step=1)
        market = st.selectbox("ì‹œì¥/ì–¸ì–´(market)", ["ko-KR", "en-US", "ja-JP"], index=0)
        st.caption("Tips: ì§ˆì˜ ì˜ˆ) íšŒì‚¬ëª… OR ë¸Œëœë“œëª… OR íŠ¹ì • ì´ìŠˆ")

        multi = st.checkbox("í™•ì¥ ê²€ìƒ‰(ë©€í‹°íŒ¨ìŠ¤)", value=True)
        target_results = st.slider("ëª©í‘œ ê²°ê³¼ ìˆ˜", 10, 50, 20, step=5)

        preset = st.toggle("ğŸ‡°ğŸ‡· í•œêµ­ ì£¼ìš” IT/ê²½ì œ ë§¤ì²´ í”„ë¦¬ì…‹ ì‚¬ìš©", value=True)
        if preset:
            preset_sites = """
    news.naver.com
    zdnet.co.kr
    it.chosun.com
    etnews.com
    hankyung.com
    mk.co.kr
    yonhapnews.co.kr
    newsis.com
    news1.kr
    bloter.net
    seoul.co.kr
    hankookilbo.com
    inews24.com
    chosun.com
    joongang.co.kr
    donga.com
    hani.co.kr
    kyunghyang.com
    mt.co.kr
    edaily.co.kr
    moneys.co.kr
    heraldcorp.com
    ohmynews.com
    pressian.com
    segye.com
    munhwa.com
    asiatoday.co.kr
    ytn.co.kr
    jtbc.co.kr
    sbs.co.kr
    kbs.co.kr
    imbc.co.kr
    tvchosun.com
    hankooki.com
    kookje.co.kr
    busan.com
    """.strip()
            sites_text = st.text_area(
                "ì‚¬ì´íŠ¸ í•„í„° (ìˆ˜ì • ê°€ëŠ¥)", preset_sites, height=150
            )
        else:
            sites_text = st.text_area("ì‚¬ì´íŠ¸ í•„í„° (ì„ íƒ, ì¤„ë°”ê¿ˆ)", "", height=80)

        submit = st.form_submit_button("ğŸ” ìŠ¤í¬ë© ì‹¤í–‰", use_container_width=True)

    st.info(
        "ì—ì´ì „íŠ¸ê°€ Grounding with Bing Searchë¥¼ í˜¸ì¶œí•´ ìµœì‹  ë‰´ìŠ¤ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.",
        icon="â„¹ï¸",
    )

    # â”€â”€ ì•¡ì…˜: ê²€ìƒ‰ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if submit:
        try:
            with st.spinner("ì—ì´ì „íŠ¸ í˜¸ì¶œ ì¤‘..."):
                compound_q = _attach_site_filters(q, sites_text)
                if multi:
                    items = search_news_multi(
                        q=compound_q,
                        count=count,
                        freshness=freshness,
                        market=market,
                        target_results=target_results,
                        max_rounds=3,
                    )
                else:
                    items = search_news(
                        q=compound_q, count=count, freshness=freshness, market=market
                    )
            st.session_state["items"] = items
            st.success(f"ê°€ì ¸ì˜¨ ê¸°ì‚¬: {len(items)}ê±´")
        except NewsError as e:
            st.error(str(e))
            st.session_state["items"] = []
        except Exception as e:
            st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            st.session_state["items"] = []

    # â”€â”€ ë Œë”: í•­ìƒ ì„¸ì…˜ ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ í‘œì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    items = st.session_state.get("items", []) or []
    if not items:
        st.warning("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆì˜ë¥¼ ë°”ê¾¸ê±°ë‚˜ ê¸°ê°„ì„ ëŠ˜ë ¤ë³´ì„¸ìš”.")
    else:
        # ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
        for it in items:
            st.markdown("---")
            st.markdown(f"**{it.get('title') or '(ì œëª© ì—†ìŒ)'}**")
            meta = f"{it.get('source') or 'ì¶œì²˜ ë¯¸ìƒ'} Â· {it.get('published') or ''}"
            st.caption(meta)
            if it.get("snippet"):
                st.write(it["snippet"])
            if it.get("url"):
                st.markdown(f"[ì›ë¬¸ ë³´ê¸°]({it['url']})")

        # ì¶œì²˜ ìš”ì•½
        st.markdown("### ğŸ“š ìˆ˜ì§‘ ì¶œì²˜ ìš”ì•½")
        counter = collections.Counter(
            _domain(it.get("url", "")) for it in items if it.get("url")
        )
        cols = st.columns(3)
        for i, (dom, cnt) in enumerate(counter.most_common(9)):
            with cols[i % 3]:
                st.write(f"- **{dom}** Ã— {cnt}")

        # â”€â”€ ë‚´ë³´ë‚´ê¸° / ì €ì¥ (CSV/JSON ë‹¤ìš´ë¡œë“œ + DOCX Blob ì—…ë¡œë“œë§Œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.markdown("### â¬‡ï¸ ë‚´ë³´ë‚´ê¸° / â˜ï¸ ì €ì¥")

        # CSV / JSON ë‹¤ìš´ë¡œë“œ
        c1, c2 = st.columns([1, 1])
        with c1:
            st.download_button(
                "CSV ë‹¤ìš´ë¡œë“œ",
                data=to_csv_bytes(items),
                file_name="pressm_news.csv",
                mime="text/csv",
                use_container_width=True,
                key="dl_csv",
            )
        with c2:
            st.download_button(
                "JSON ë‹¤ìš´ë¡œë“œ",
                data=json.dumps(items, ensure_ascii=False, indent=2).encode("utf-8"),
                file_name="pressm_news.json",
                mime="application/json",
                use_container_width=True,
                key="dl_json",
            )

        # â”€â”€ DOCX ì—…ë¡œë“œ ì „ìš© UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.markdown("### ğŸ§¾ DOCXë¥¼ Blobì— ì—…ë¡œë“œ")

        # íŒŒì¼ëª… ì œì•ˆ (ì¿¼ë¦¬ ê¸°ì¤€ + ë‚ ì§œ)
        suggest_name = make_docx_filename_from_query(q, include_date=True)

        # ì‚¬ìš©ìê°€ ê²½ë¡œ ìˆ˜ì • ê°€ëŠ¥(ì»¨í…Œì´ë„ˆ ë‚´ ê²½ë¡œ)
        docx_blob_path = st.text_input(
            "DOCX íŒŒì¼ ê²½ë¡œ (ì»¨í…Œì´ë„ˆ ë‚´, ê¸°ë³¸: docx/â€¦):",
            value=suggest_name,
            help="ì˜ˆ: docx/KT_20251030.docx â€” ë°˜ë“œì‹œ 'docx/' ì•„ë˜ì— ì €ì¥ë©ë‹ˆë‹¤.",
        )

        # DOCX ìƒì„±
        generated_at = __import__("datetime").datetime.now().__str__()
        docx_bytes = generate_docx_bytes(
            items,
            title="Pressm AI â€” ë‰´ìŠ¤ ìŠ¤í¬ë© ë¦¬í¬íŠ¸",
            query=q,
            freshness=freshness,
            market=market,
            generated_at=generated_at,
        )

        # ì—…ë¡œë“œ ë²„íŠ¼ (ì—…ë¡œë“œë§Œ ë‚¨ê¹€)
        if st.button(
            "â˜ï¸ DOCXë¥¼ Blobì— ì—…ë¡œë“œ", use_container_width=True, key="upload_docx_btn"
        ):
            try:
                with st.spinner("DOCX ì—…ë¡œë“œ ì¤‘..."):
                    path = (docx_blob_path or "").strip()
                    if not path or not path.lower().startswith("docx/"):
                        path = "docx/" + (path or "pressm_report.docx")
                    if not path.lower().endswith(".docx"):
                        path += ".docx"

                    container, blob = upload_docx(docx_bytes, path)
                    link = sas_url(container, blob, minutes=120) or public_blob_url(
                        container, blob
                    )

                    st.session_state["docx_blob_info"] = {
                        "container": container,
                        "blob": blob,
                        "link": link,
                    }
                st.success("DOCX ì—…ë¡œë“œ ì™„ë£Œ! ì•„ë˜ ë§í¬ë¡œ ì—´ê±°ë‚˜ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆì–´ìš”.")
                st.rerun()  # ì—…ë¡œë“œ í›„ ì¦‰ì‹œ ì¬ë Œë”ë§í•˜ì—¬ ë§í¬/ë²„íŠ¼ ë…¸ì¶œ
            except Exception as e:
                import traceback

                st.error(f"DOCX ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
                st.exception(traceback.format_exc())

        # ì—…ë¡œë“œ ê²°ê³¼ í‘œì‹œ (ì„¸ì…˜ ìœ ì§€)
        docx_blob_info = st.session_state.get("docx_blob_info")
        if docx_blob_info:
            st.info(
                f"DOCX Blob ê²½ë¡œ: `{docx_blob_info['container']}/{docx_blob_info['blob']}`"
            )
            # ìƒˆ íƒ­ìœ¼ë¡œ ì—´ê¸°(ê¶Œì¥: SAS ìˆìœ¼ë©´ ë°”ë¡œ ì—´ë¦¼)
            st.markdown(
                f'<a href="{docx_blob_info["link"]}" target="_blank" rel="noopener noreferrer">ğŸ”— DOCX ë§í¬ ìƒˆ íƒ­ìœ¼ë¡œ ì—´ê¸°</a>',
                unsafe_allow_html=True,
            )

            # Blobì—ì„œ ì§ì ‘ ë‚´ë ¤ë°›ê¸°(ì•± ë‚´ ë²„íŠ¼) â€” SAS/í¼ë¸”ë¦­ ì—¬ë¶€ ê´€ê³„ì—†ì´ ì‹œë„
            data_docx = None
            try:
                data_docx = download_bytes(
                    docx_blob_info["container"], docx_blob_info["blob"]
                )
            except Exception as e:
                st.warning(f"Blob DOCX ì§ì ‘ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            if data_docx:
                st.download_button(
                    label="ğŸ“¥ Blobì—ì„œ DOCX ì§ì ‘ ë‹¤ìš´ë¡œë“œ",
                    data=data_docx,
                    file_name=docx_blob_info["blob"].split("/")[-1],
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    use_container_width=True,
                    key="dl_docx_blob_direct",
                )
